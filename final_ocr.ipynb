{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ca9a81",
   "metadata": {},
   "source": [
    "# Projet d'impléméntation d'OCR avec Keras_OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Dependances néccéssaires à installer pour importer la classe:\n",
    "        !pip install -q keras-ocr : Module principale de notre projet\n",
    "        !pip install pyspellchecker : Pour la correction orthographique des prédictions (en francais et en anglais)\n",
    "        !pip install fuzzywuzzy : Pour determiner la précision de la correction orthographique\n",
    "    \n",
    "\"\"\"\n",
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from spellchecker import SpellChecker\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bc491",
   "metadata": {},
   "source": [
    "# Construction de la classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a02bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCR() :\n",
    "  def __init__(self, language='fr'):\n",
    "    self.pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    self.spell = SpellChecker(language=language)\n",
    "    self.fuzzy = fuzz\n",
    "\n",
    "    # Prend le chemin d'accès d'une image en entrée\n",
    "  def read_images(self, image_path):\n",
    "    images = [keras_ocr.tools.read(image_path)]\n",
    "    return images\n",
    "\n",
    "    #Pour la reconnaissance de texte\n",
    "  def recognize_text(self, images):\n",
    "    prediction_groups = self.pipeline.recognize(images)\n",
    "    return prediction_groups\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Permet d'afficher l'image avec les différentes valeurs prédites.\n",
    "        Elle prend en entrée l'image lue par 'read_image' et les prédictions\n",
    "    \"\"\"\n",
    "  def plot_predictions(self, images, prediction_groups):\n",
    "      fig, axs = plt.subplots(nrows=len(images), figsize=(10, 20))\n",
    "      if len(images) == 1:\n",
    "          axs = [axs]\n",
    "      for ax, image, predictions in zip(axs, images, prediction_groups):\n",
    "          keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)\n",
    "\n",
    "    #Fonction permettant d'obtenir que les prédictions ou textes prédits par le modèle\n",
    "  def get_text(self, prediction_groups_part):\n",
    "    texts = []\n",
    "    info_image = prediction_groups_part\n",
    "    for text, box in info_image :\n",
    "      texts.append(text)\n",
    "    return texts\n",
    "\n",
    "\n",
    "    \"\"\"Fonction qui calcule le niveau de différence entre deux mots.\n",
    "        Utilisée pour determiner le niveau de précision de la correction orthographique\n",
    "    \"\"\"\n",
    "  def similarity_word(self, word, corrected_word):\n",
    "    return self.fuzzy.ratio(word, corrected_word) / 100.0\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Permet la correction orthographique d'un ensemble de mots de la variable 'text'.\n",
    "        Prend en entrée le texte entier et la langue de correction ('fr' ou 'en')\n",
    "        Donne en sortie le texte corrigé et le niveau de précision de la correction\n",
    "    \"\"\"\n",
    "  def correct_spelling(self, text, language):\n",
    "      words = text.split()\n",
    "      corrected_words = []\n",
    "      similarity_words = []\n",
    "\n",
    "      for word in words:\n",
    "          corrected_word = self.spell.correction(word)\n",
    "          similarity = self.similarity_word(word, corrected_word)\n",
    "\n",
    "          # Vérifie si le mot corrigé n'est pas None et est de type str\n",
    "          if corrected_word is not None and isinstance(corrected_word, str):\n",
    "            corrected_words.append(corrected_word)\n",
    "            similarity_words.append(similarity)\n",
    "\n",
    "\n",
    "      corrected_text = \" \".join(corrected_words)\n",
    "      if corrected_text == '' :\n",
    "        similarity = 0\n",
    "      else :\n",
    "        similarity = max(similarity_words)\n",
    "      return corrected_text, similarity\n",
    "\n",
    "\n",
    "    \n",
    "       # Permet d'obtenir une liste de tuple de la forme i, j, k\n",
    "        #i  La valeure prédite par le modele\n",
    "        #j  Sa valeure corrigée\n",
    "        #k  Le niveau de précidion de la correction\n",
    "    \n",
    "  def get_all(self, texts):\n",
    "    Mots = []\n",
    "    score = []\n",
    "    donnees = []\n",
    "\n",
    "    for i in range(len(texts)) :\n",
    "      corrected_text_1, similarity_score_1 = self.correct_spelling(texts[i], 'en')  \n",
    "      corrected_text_2, similarity_score_2 = self.correct_spelling(texts[i], 'fr')\n",
    "\n",
    "      if similarity_score_1 > similarity_score_2 :\n",
    "        corrected_text = corrected_text_1\n",
    "        similarity_score = similarity_score_1\n",
    "      else :\n",
    "        corrected_text = corrected_text_2\n",
    "        similarity_score = similarity_score_2\n",
    "\n",
    "      Mots.append(corrected_text)\n",
    "      score.append(similarity_score)\n",
    "\n",
    "    for i,j,k in zip(texts, Mots, score) :\n",
    "      lien = (i, j, k)\n",
    "      donnees.append(lien)\n",
    "\n",
    "    return donnees\n",
    "\n",
    "    \"\"\"\n",
    "        Faire le tout en un. \n",
    "        Du path de l'image à l'ensemble de données sur la prédiction, la correction (en 'en' et 'fr') et la précision.\n",
    "        - 'show' est une variable booleenne qui permet d'afficher ou non l'image avec les prédictions dessus\n",
    "    \"\"\"\n",
    "  def all_in_one_OCR(self, image_path, show):\n",
    "    all_infos = {}\n",
    "    images = self.read_images(image_path)\n",
    "    prediction_groups = self.recognize_text(images)\n",
    "    if show == True :\n",
    "      self.plot_predictions(images, prediction_groups)\n",
    "    n = len(prediction_groups)\n",
    "    for i in range(n) :\n",
    "      texts = self.get_text(prediction_groups[i])\n",
    "      donnees = self.get_all(texts)\n",
    "      all_infos[f\"Image {i}\"] = donnees\n",
    "    return all_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ea156",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c1898",
   "metadata": {},
   "source": [
    "## 1) Chargement de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de463ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = tf.keras.utils.get_file(\n",
    "'img1.jpg',\n",
    "'https://prod.cdn-medias.jeuneafrique.com/cdn-cgi/image/q=auto,f=auto,metadata=none,width=1215,fit=cover/https://prod.cdn-medias.jeuneafrique.com/medias/2021/01/12/jad20210112-ass-cameroun-carte-identite.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31df3fd",
   "metadata": {},
   "source": [
    "## 2) Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a7df74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\Fred\\.keras-ocr\\craft_mlt_25k.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16860/528969318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Création d'une instance de la classe OCR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mocr_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOCR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[0;32m      5\u001b[0m     \u001b[0mPour\u001b[0m \u001b[0mune\u001b[0m \u001b[0mimportation\u001b[0m \u001b[0mde\u001b[0m \u001b[0mla\u001b[0m \u001b[0mclasse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaire\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16860/193390630.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, language)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mOCR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuzzy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_ocr\\pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, detector, recognizer, scale, max_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecognizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mrecognizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_ocr\\recognition.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, alphabet, weights, build_params)\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m         ) = build_model(alphabet=alphabet, **build_params)\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[0mweights_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPRETRAINED_WEIGHTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_ocr\\recognition.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(alphabet, height, width, color, filters, rnn_units, dropout, rnn_steps_to_discard, pool_size, stn)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mlocnet_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocnet_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mlocnet_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocnet_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         locnet_y = keras.layers.Dense(\n\u001b[0m\u001b[0;32m    278\u001b[0m             \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             weights=[\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     ):\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    265\u001b[0m                 \u001b[1;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[1;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}"
     ]
    }
   ],
   "source": [
    "# Création d'une instance de la classe OCR\n",
    "ocr_instance = OCR('fr')\n",
    "\n",
    "\"\"\"\n",
    "    Pour une importation de la classe, faire :\n",
    "        from \"nom_du_fichier_python_portant_cette_classe\" import OCR\n",
    "        ex : from final_ocr import OCR\n",
    "        \n",
    "        ocr_instance = OCR('fr') ou ocr_instance = OCR('en')\n",
    "\"\"\"\n",
    "\n",
    "# Appel de la méthode all_in_one_OCR avec l'image img1\n",
    "resultat = ocr_instance.all_in_one_OCR(img1, True)\n",
    "\n",
    "# Affichage du résultat\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b14a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055409f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d74415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
